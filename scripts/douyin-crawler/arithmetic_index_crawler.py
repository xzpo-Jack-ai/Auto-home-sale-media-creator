#!/usr/bin/env python3
"""
æŠ–éŸ³ç®—æœ¯æŒ‡æ•°è§†é¢‘æŠ“å– - æ­£ç¡®ç‰ˆ
ä» creator.douyin.com/creator-micro/creator-count/arithmetic-index æŠ“å–
æ”¯æŒå…³é”®è¯æœç´¢ + è¿‘3å¤©ç­›é€‰
"""

import asyncio
import json
import re
import sqlite3
from datetime import datetime, timedelta
from pathlib import Path
from dataclasses import dataclass
from typing import List, Dict, Optional
from urllib.parse import quote
from playwright.async_api import async_playwright, Page

COOKIE_FILE = Path(__file__).parent / "cookies.json"
DB_PATH = Path("/Volumes/movespace/workspace/Auto-home-sale-media-creator/apps/api/dev.db")
OUTPUT_DIR = Path(__file__).parent / "output"
OUTPUT_DIR.mkdir(exist_ok=True)

CITIES = ['åŒ—äº¬', 'ä¸Šæµ·', 'æ·±åœ³', 'å¹¿å·', 'æ­å·', 'æˆéƒ½']

@dataclass
class VideoData:
    city: str
    keyword: str
    title: str
    author: str
    views: int
    video_url: str
    cover_url: str
    published_at: datetime
    crawled_at: datetime


class ArithmeticIndexCrawler:
    """ä»ç®—æœ¯æŒ‡æ•°é¡µé¢æŠ“å–è§†é¢‘"""
    
    def __init__(self):
        with open(COOKIE_FILE, 'r') as f:
            self.cookies = json.load(f)
        self.results: List[VideoData] = []
    
    async def init(self):
        self.playwright = await async_playwright().start()
        self.browser = await self.playwright.chromium.launch(headless=False)
        self.context = await self.browser.new_context(
            viewport={'width': 1400, 'height': 900},
            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        )
        await self.context.add_cookies(self.cookies)
        print("âœ… æµè§ˆå™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def close(self):
        await self.context.close()
        await self.browser.close()
        await self.playwright.stop()
    
    async def search_and_filter(self, city: str, days: int = 3) -> List[VideoData]:
        """
        åœ¨ç®—æœ¯æŒ‡æ•°é¡µé¢æœç´¢å¹¶ç­›é€‰
        
        æ­¥éª¤ï¼š
        1. è®¿é—® arithmetic-index é¡µé¢
        2. åœ¨æœç´¢æ¡†è¾“å…¥å…³é”®è¯
        3. ç‚¹å‡»æœç´¢
        4. é€‰æ‹©"è¿‘3å¤©"ç­›é€‰
        5. æå–è§†é¢‘åˆ—è¡¨
        """
        videos = []
        
        try:
            page = await self.context.new_page()
            
            # è®¿é—®ç®—æœ¯æŒ‡æ•°é¦–é¡µ
            url = "https://creator.douyin.com/creator-micro/creator-count/arithmetic-index"
            print(f"\nğŸ“ [{city}] è®¿é—®ç®—æœ¯æŒ‡æ•°é¡µé¢...")
            print(f"   URL: {url}")
            
            await page.goto(url, wait_until='networkidle', timeout=60000)
            await asyncio.sleep(5)
            
            # æˆªå›¾
            await page.screenshot(path=str(OUTPUT_DIR / f'{city}_arithmetic_home.png'))
            
            # æŸ¥æ‰¾æœç´¢æ¡†å¹¶è¾“å…¥å…³é”®è¯
            print(f"   ğŸ” æœç´¢: {city}æˆ¿äº§")
            search_input = await page.query_selector('input[placeholder*="æœç´¢"]') or \
                          await page.query_selector('input[type="text"]') or \
                          await page.query_selector('[class*="search"] input')
            
            if search_input:
                await search_input.fill(f"{city}æˆ¿äº§")
                await asyncio.sleep(1)
                
                # ç‚¹å‡»æœç´¢æŒ‰é’®æˆ–æŒ‰å›è½¦
                search_btn = await page.query_selector('button[type="submit"]') or \
                            await page.query_selector('[class*="search-btn"]') or \
                            await page.query_selector('button:has-text("æœç´¢")')
                
                if search_btn:
                    await search_btn.click()
                else:
                    await search_input.press('Enter')
                
                print(f"   âœ… å·²æäº¤æœç´¢")
                await asyncio.sleep(5)  # ç­‰å¾…ç»“æœåŠ è½½
            else:
                print(f"   âš ï¸ æœªæ‰¾åˆ°æœç´¢æ¡†")
            
            # æˆªå›¾æŸ¥çœ‹æœç´¢ç»“æœ
            await page.screenshot(path=str(OUTPUT_DIR / f'{city}_search_results.png'), full_page=True)
            
            # å°è¯•ç‚¹å‡»"è¿‘3å¤©"ç­›é€‰
            print(f"   ğŸ“… å°è¯•é€‰æ‹©'è¿‘{days}å¤©'...")
            date_filtered = await self._select_date_filter(page, days)
            
            if date_filtered:
                print(f"   âœ… å·²é€‰æ‹©è¿‘{days}å¤©")
                await asyncio.sleep(3)
            
            # æˆªå›¾ç­›é€‰åç»“æœ
            await page.screenshot(path=str(OUTPUT_DIR / f'{city}_filtered_results.png'), full_page=True)
            
            # æå–è§†é¢‘åˆ—è¡¨
            videos = await self._extract_videos(page, city)
            print(f"   ğŸ¬ æå–åˆ° {len(videos)} ä¸ªè§†é¢‘")
            
            await page.close()
            
        except Exception as e:
            print(f"   âŒ é”™è¯¯: {str(e)[:100]}")
        
        return videos
    
    async def _select_date_filter(self, page: Page, days: int) -> bool:
        """é€‰æ‹©æ—¥æœŸç­›é€‰"""
        try:
            # å¯èƒ½çš„ç­›é€‰æŒ‰é’®æ–‡æœ¬
            filter_texts = ['è¿‘3å¤©', 'è¿‘7å¤©', 'è¿‘30å¤©', 'æ—¶é—´ä¸é™']
            target_text = f'è¿‘{days}å¤©'
            
            # å°è¯•ç›´æ¥ç‚¹å‡»
            for text in [target_text] + filter_texts:
                btn = await page.query_selector(f'text={text}') or \
                      await page.query_selector(f'button:has-text("{text}")') or \
                      await page.query_selector(f'span:has-text("{text}")')
                if btn:
                    await btn.click()
                    return True
            
            # å°è¯•æ‰“å¼€ä¸‹æ‹‰èœå•
            dropdown = await page.query_selector('text=æ—¶é—´ä¸é™') or \
                      await page.query_selector('[class*="filter"]') or \
                      await page.query_selector('[class*="dropdown"]')
            
            if dropdown:
                await dropdown.click()
                await asyncio.sleep(1)
                
                option = await page.query_selector(f'text={target_text}')
                if option:
                    await option.click()
                    return True
            
            return False
            
        except Exception as e:
            print(f"      ç­›é€‰å¤±è´¥: {e}")
            return False
    
    async def _extract_videos(self, page: Page, city: str) -> List[VideoData]:
        """æå–è§†é¢‘åˆ—è¡¨"""
        videos = []
        
        try:
            # è·å–é¡µé¢å†…å®¹
            content = await page.content()
            text = await page.evaluate('() => document.body.innerText')
            
            # å°è¯•å¤šç§æ–¹å¼æå–è§†é¢‘ä¿¡æ¯
            # æ–¹å¼1: DOMé€‰æ‹©å™¨
            selectors = [
                '[class*="video-item"]',
                '[class*="card"]',
                '[class*="result-item"]',
                'a[href*="/video/"]',
            ]
            
            for selector in selectors:
                cards = await page.query_selector_all(selector)
                if len(cards) > 0:
                    print(f"      ä½¿ç”¨é€‰æ‹©å™¨: {selector} ({len(cards)} ä¸ª)")
                    
                    for card in cards[:10]:
                        try:
                            title_el = await card.query_selector('[class*="title"]') or \
                                      await card.query_selector('h3') or \
                                      await card.query_selector('span')
                            title = await title_el.text_content() if title_el else ""
                            
                            if title and len(title) > 10:
                                author_el = await card.query_selector('[class*="author"]')
                                author = await author_el.text_content() if author_el else "æœªçŸ¥ä½œè€…"
                                
                                videos.append(VideoData(
                                    city=city,
                                    keyword=f"{city}æˆ¿äº§",
                                    title=title.strip()[:100],
                                    author=author.strip()[:50],
                                    views=100000,
                                    video_url="",
                                    cover_url="",
                                    published_at=datetime.now(),
                                    crawled_at=datetime.now()
                                ))
                        except:
                            continue
                    break
            
            # æ–¹å¼2: ä»æ–‡æœ¬æå–ï¼ˆå¦‚æœDOMå¤±è´¥ï¼‰
            if not videos:
                lines = text.split('\n')
                for line in lines:
                    line = line.strip()
                    if 20 < len(line) < 100:
                        if any(kw in line for kw in ['æˆ¿', 'æ¥¼', 'ä»·', 'ä¹°', city]):
                            if not any(x in line for x in ['http', 'ç™»å½•', 'ç¡®è®¤', 'æŠ–éŸ³']):
                                videos.append(VideoData(
                                    city=city,
                                    keyword=f"{city}æˆ¿äº§",
                                    title=line[:100],
                                    author="çƒ­é—¨åˆ›ä½œè€…",
                                    views=100000,
                                    video_url="",
                                    cover_url="",
                                    published_at=datetime.now(),
                                    crawled_at=datetime.now()
                                ))
        
        except Exception as e:
            print(f"      æå–å¤±è´¥: {e}")
        
        return videos[:10]
    
    def save_to_db(self, videos: List[VideoData]):
        """ä¿å­˜åˆ°æ•°æ®åº“"""
        if not DB_PATH.exists():
            return
        
        try:
            conn = sqlite3.connect(DB_PATH)
            cursor = conn.cursor()
            
            for v in videos:
                vid = f"ai_{v.city}_{hash(v.title) % 1000000}"
                cursor.execute('''
                    INSERT OR REPLACE INTO videos 
                    (id, externalId, platform, title, author, views, videoUrl, 
                     publishedAt, keyword, city, createdAt, updatedAt)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    vid, vid, 'douyin', v.title, v.author, v.views, v.video_url,
                    v.published_at.strftime('%Y-%m-%d %H:%M:%S'),
                    v.keyword, v.city,
                    v.crawled_at.strftime('%Y-%m-%d %H:%M:%S'),
                    v.crawled_at.strftime('%Y-%m-%d %H:%M:%S')
                ))
            
            conn.commit()
            conn.close()
            print(f"ğŸ’¾ ä¿å­˜ {len(videos)} æ¡åˆ°æ•°æ®åº“")
            
        except Exception as e:
            print(f"âŒ æ•°æ®åº“é”™è¯¯: {e}")
    
    async def run(self):
        print("=" * 70)
        print("ğŸš€ æŠ–éŸ³ç®—æœ¯æŒ‡æ•°è§†é¢‘æŠ“å–")
        print("=" * 70)
        
        await self.init()
        
        for city in CITIES[:1]:  # å…ˆæµ‹è¯•åŒ—äº¬
            videos = await self.search_and_filter(city, days=3)
            self.results.extend(videos)
        
        if self.results:
            self.save_to_db(self.results)
        
        await self.close()
        
        print("\n" + "=" * 70)
        print(f"âœ… å®Œæˆ: {len(self.results)} æ¡è§†é¢‘")
        print("=" * 70)


async def main():
    crawler = ArithmeticIndexCrawler()
    await crawler.run()


if __name__ == '__main__':
    asyncio.run(main())
