#!/usr/bin/env python3
"""
ç›´æ¥æå–æŠ–éŸ³è§†é¢‘ä¿¡æ¯ï¼ˆç»•è¿‡ yt-dlpï¼‰
ä½¿ç”¨ Playwright æ§åˆ¶ Chrome è®¿é—®è§†é¢‘é¡µé¢å¹¶æå–ä¿¡æ¯
"""

import asyncio
import json
import re
import sys

async def extract_video_info(video_url: str):
    from playwright.async_api import async_playwright
    
    cookies_path = "/Volumes/movespace/workspace/Auto-home-sale-media-creator/apps/api/cookies/douyin.txt"
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(
            headless=False,
            executable_path='/Applications/Google Chrome.app/Contents/MacOS/Google Chrome',
            args=['--disable-blink-features=AutomationControlled']
        )
        
        # åŠ è½½ cookies
        context = await browser.new_context(
            viewport={'width': 1280, 'height': 800}
        )
        
        # ä»æ–‡ä»¶åŠ è½½ cookies
        try:
            with open(cookies_path, 'r') as f:
                lines = f.readlines()
            
            cookies = []
            for line in lines:
                line = line.strip()
                if not line or line.startswith('#'):
                    continue
                
                parts = line.split('\t')
                if len(parts) >= 7:
                    cookies.append({
                        'domain': parts[0],
                        'path': parts[2],
                        'name': parts[5],
                        'value': parts[6],
                        'secure': parts[3].upper() == 'TRUE',
                        'httpOnly': False,
                        'sameSite': 'Lax'
                    })
            
            if cookies:
                await context.add_cookies(cookies)
                print(f"âœ… å·²åŠ è½½ {len(cookies)} ä¸ª cookies")
        except Exception as e:
            print(f"âš ï¸  åŠ è½½ cookies å¤±è´¥: {e}")
        
        page = await context.new_page()
        
        print(f"ğŸš€ æ‰“å¼€è§†é¢‘é¡µé¢: {video_url}")
        await page.goto(video_url, timeout=60000)
        await asyncio.sleep(5)  # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
        
        # å°è¯•æå–è§†é¢‘ä¿¡æ¯
        video_info = {
            'url': video_url,
            'title': None,
            'author': None,
            'transcript': None
        }
        
        # æ–¹æ³•1: ä»é¡µé¢è„šæœ¬æå– SSR æ•°æ®
        try:
            # æŸ¥æ‰¾ RENDER_DATA
            render_data = await page.evaluate('''() => {
                const script = document.querySelector('script[id="RENDER_DATA"]');
                return script ? script.textContent : null;
            }''')
            
            if render_data:
                print("âœ… æ‰¾åˆ° RENDER_DATA")
                # è§£æ JSON æ•°æ®
                try:
                    import urllib.parse
                    decoded = urllib.parse.unquote(render_data)
                    data = json.loads(decoded)
                    
                    # è°ƒè¯•: ä¿å­˜æ•°æ®ç»“æ„
                    with open('/tmp/douyin_debug.json', 'w') as f:
                        json.dump(data, f, ensure_ascii=False, indent=2)
                    print("ğŸ’¾ æ•°æ®ç»“æ„å·²ä¿å­˜åˆ° /tmp/douyin_debug.json")
                    
                    # æå–è§†é¢‘ä¿¡æ¯
                    app_data = data.get('app', {}) or data
                    print(f"ğŸ” æ•°æ®é”®: {list(app_data.keys())[:10]}")
                    video_detail = app_data.get('videoDetail') or app_data.get('aweme_detail') or {}
                    
                    if video_detail:
                        video_info['title'] = video_detail.get('desc') or video_detail.get('title')
                        video_info['author'] = video_detail.get('author', {}).get('nickname')
                        video_info['duration'] = video_detail.get('duration')
                        
                        # æå–å­—å¹•
                        subtitles = video_detail.get('subtitleInfos', [])
                        if subtitles:
                            transcript_lines = []
                            for sub in sorted(subtitles, key=lambda x: x.get('startTime', 0)):
                                text = sub.get('content', '').strip()
                                if text:
                                    transcript_lines.append(text)
                            
                            video_info['transcript'] = '\n'.join(transcript_lines)
                            print(f"ğŸ“ æå–åˆ° {len(subtitles)} æ¡å­—å¹•")
                        
                        print(f"ğŸ“„ æ ‡é¢˜: {video_info['title'][:50]}...")
                        print(f"ğŸ‘¤ ä½œè€…: {video_info['author']}")
                except Exception as e:
                    print(f"è§£æ RENDER_DATA å¤±è´¥: {e}")
                    # ä¿å­˜åŸå§‹æ•°æ®ç”¨äºè°ƒè¯•
                    with open('/tmp/douyin_render_data.json', 'w') as f:
                        f.write(decoded if 'decoded' in locals() else render_data)
                    print("ğŸ’¾ åŸå§‹æ•°æ®å·²ä¿å­˜åˆ° /tmp/douyin_render_data.json")
                    import traceback
                    traceback.print_exc()
        except Exception as e:
            print(f"æå– RENDER_DATA å¤±è´¥: {e}")
        
        # æ–¹æ³•2: ä»é¡µé¢ HTML æå–æ ‡é¢˜å’Œä½œè€…
        try:
            title = await page.title()
            video_info['title'] = title
            print(f"ğŸ“„ é¡µé¢æ ‡é¢˜: {title}")
        except:
            pass
        
        # æ–¹æ³•3: æŸ¥æ‰¾å­—å¹•æŒ‰é’®å¹¶ç‚¹å‡»
        try:
            # å¯»æ‰¾å­—å¹•/æ–‡æ¡ˆç›¸å…³æŒ‰é’®
            subtitle_btn = await page.query_selector('[data-e2e="subtitle-btn"], .subtitle-btn, [class*="subtitle"]')
            if subtitle_btn:
                print("âœ… æ‰¾åˆ°å­—å¹•æŒ‰é’®ï¼Œç‚¹å‡»...")
                await subtitle_btn.click()
                await asyncio.sleep(2)
                
                # å°è¯•è·å–å­—å¹•å†…å®¹
                subtitle_text = await page.evaluate('''() => {
                    const elements = document.querySelectorAll('[class*="subtitle"] [class*="text"], .subtitle-content, [data-e2e="subtitle-text"]');
                    return Array.from(elements).map(el => el.textContent).join('\\n');
                }''')
                
                if subtitle_text:
                    video_info['transcript'] = subtitle_text
                    print(f"ğŸ“ æå–åˆ°å­—å¹•: {subtitle_text[:200]}...")
        except Exception as e:
            print(f"æå–å­—å¹•å¤±è´¥: {e}")
        
        # ä¿å­˜å½“å‰ cookiesï¼ˆåˆ·æ–°åçš„ï¼‰
        try:
            current_cookies = await context.cookies()
            cookie_lines = ["# Netscape HTTP Cookie File", "# Auto-generated", ""]
            
            for cookie in current_cookies:
                domain = cookie['domain']
                flag = "TRUE" if domain.startswith('.') else "FALSE"
                path = cookie['path']
                secure = "TRUE" if cookie['secure'] else "FALSE"
                expiration = str(int(cookie.get('expires', 0))) if cookie.get('expires') else "0"
                name = cookie['name']
                value = cookie['value']
                
                cookie_lines.append(f"{domain}\t{flag}\t{path}\t{secure}\t{expiration}\t{name}\t{value}")
            
            with open(cookies_path, 'w') as f:
                f.write('\n'.join(cookie_lines))
            print(f"âœ… å·²æ›´æ–° cookies: {len(current_cookies)} ä¸ª")
        except Exception as e:
            print(f"ä¿å­˜ cookies å¤±è´¥: {e}")
        
        await browser.close()
        return video_info

if __name__ == "__main__":
    url = sys.argv[1] if len(sys.argv) > 1 else "https://v.douyin.com/od9jc8Ju4t8/"
    
    try:
        result = asyncio.run(extract_video_info(url))
        print("\n" + "="*50)
        print("æå–ç»“æœ:")
        print(json.dumps(result, ensure_ascii=False, indent=2))
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
