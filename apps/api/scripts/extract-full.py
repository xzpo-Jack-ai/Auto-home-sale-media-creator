#!/usr/bin/env python3
"""
æŠ–éŸ³è§†é¢‘å­—å¹•æå– - å¸¦æ–°é²œCookiesè·å–

æµç¨‹:
1. Playwright ç™»å½•æŠ–éŸ³è·å–æ–°é²œ cookies
2. å°è¯• API æ‹¦æˆªæå–å­—å¹•
3. è‹¥æ— å­—å¹•ï¼Œç”¨ yt-dlp (å¸¦æ–°é²œcookies) ä¸‹è½½éŸ³é¢‘
4. Whisper ASR è½¬å†™
"""

import asyncio
import json
import sys
import os
import tempfile
import subprocess

async def extract_with_fresh_cookies(video_url: str):
    from playwright.async_api import async_playwright
    
    cookies_path = "/Volumes/movespace/workspace/Auto-home-sale-media-creator/apps/api/cookies/douyin.txt"
    
    async with async_playwright() as p:
        # å¯åŠ¨æµè§ˆå™¨ï¼ˆæœ‰å¤´æ¨¡å¼ï¼Œå¯ä»¥çœ‹åˆ°ç™»å½•é¡µé¢ï¼‰
        browser = await p.chromium.launch(
            headless=False,
            executable_path='/Applications/Google Chrome.app/Contents/MacOS/Google Chrome',
            args=['--disable-blink-features=AutomationControlled']
        )
        
        context = await browser.new_context(viewport={'width': 1280, 'height': 800})
        page = await context.new_page()
        
        print("ğŸš€ æ‰“å¼€æŠ–éŸ³...")
        await page.goto("https://www.douyin.com/", timeout=60000)
        await asyncio.sleep(3)
        
        # æ£€æŸ¥æ˜¯å¦å·²ç™»å½•
        try:
            avatar = await page.wait_for_selector("img[src*='avatar'], [data-e2e='user-avatar']", timeout=5000)
            if avatar:
                print("âœ… æ£€æµ‹åˆ°å·²ç™»å½•")
        except:
            print("âš ï¸  æœªç™»å½•ï¼Œè¯·åœ¨æµè§ˆå™¨ä¸­æ‰«ç æˆ–ç™»å½•")
            print("â³ ç­‰å¾…60ç§’...")
            await asyncio.sleep(60)
        
        # ä¿å­˜æ–°é²œ cookies
        cookies = await context.cookies()
        cookie_lines = ["# Netscape HTTP Cookie File", "# Auto-generated", ""]
        
        for cookie in cookies:
            domain = cookie['domain']
            flag = "TRUE" if domain.startswith('.') else "FALSE"
            path = cookie['path']
            secure = "TRUE" if cookie['secure'] else "FALSE"
            expiration = str(int(cookie.get('expires', 0))) if cookie.get('expires') else "0"
            name = cookie['name']
            value = cookie['value']
            cookie_lines.append(f"{domain}\t{flag}\t{path}\t{secure}\t{expiration}\t{name}\t{value}")
        
        with open(cookies_path, 'w') as f:
            f.write('\n'.join(cookie_lines))
        print(f"âœ… å·²æ›´æ–° cookies: {len(cookies)} ä¸ª")
        
        # å…³é—­æµè§ˆå™¨
        await browser.close()
        
        # ç°åœ¨ç”¨ API æ‹¦æˆªæå–
        print("\nğŸ¬ å¼€å§‹æå–è§†é¢‘...")
        result = await extract_video(video_url, cookies_path)
        
        return result


async def extract_video(video_url: str, cookies_path: str):
    """æå–è§†é¢‘ä¿¡æ¯"""
    from playwright.async_api import async_playwright
    
    result = {
        'url': video_url,
        'title': None,
        'author': None,
        'duration': None,
        'transcript': None,
        'source': None,
        'error': None
    }
    
    captured_data = {}
    audio_url_holder = [None]
    
    async def handle_route(route):
        url = route.request.url
        if '/aweme/v1/web/aweme/detail/' in url:
            response = await route.fetch()
            body = await response.body()
            try:
                data = json.loads(body)
                captured_data['video_detail'] = data
                aweme = data.get('aweme_detail', {})
                video = aweme.get('video', {})
                play_addr = video.get('play_addr', {})
                if play_addr.get('url_list'):
                    audio_url_holder[0] = play_addr['url_list'][0]
            except:
                pass
            await route.fulfill(response=response)
        else:
            await route.continue_()
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(
            headless=True,  # æ— å¤´æ¨¡å¼æ›´å¿«
            executable_path='/Applications/Google Chrome.app/Contents/MacOS/Google Chrome'
        )
        
        context = await browser.new_context(viewport={'width': 1280, 'height': 800})
        
        # åŠ è½½ cookies
        with open(cookies_path, 'r') as f:
            lines = f.readlines()
        
        cookies = []
        for line in lines:
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            parts = line.split('\t')
            if len(parts) >= 7:
                cookies.append({
                    'domain': parts[0],
                    'path': parts[2],
                    'name': parts[5],
                    'value': parts[6],
                    'secure': parts[3].upper() == 'TRUE',
                    'httpOnly': False,
                    'sameSite': 'Lax'
                })
        
        await context.add_cookies(cookies)
        
        page = await context.new_page()
        await page.route("**/*", handle_route)
        
        print(f"ğŸ¯ æ­£åœ¨æå–: {video_url}")
        try:
            await page.goto(video_url, timeout=30000, wait_until='domcontentloaded')
        except:
            pass
        
        # ç­‰å¾… API
        for i in range(10):
            if 'video_detail' in captured_data:
                break
            await asyncio.sleep(1)
        
        # è§£æç»“æœ
        if 'video_detail' in captured_data:
            aweme = captured_data['video_detail'].get('aweme_detail', {})
            result['title'] = aweme.get('desc')
            result['author'] = aweme.get('author', {}).get('nickname')
            duration = aweme.get('duration', 0)
            if duration > 1000:
                duration = duration / 1000
            result['duration'] = int(duration)
            
            # æ£€æŸ¥å­—å¹•
            subtitles = aweme.get('subtitle_infos', [])
            if subtitles:
                lines = [s.get('content', '').strip() for s in sorted(subtitles, key=lambda x: x.get('start_time', 0))]
                result['transcript'] = '\n'.join([l for l in lines if l])
                result['source'] = 'subtitle'
                print(f"âœ… æå–åˆ°è‡ªåŠ¨å­—å¹• ({len(subtitles)} æ¡)")
            elif audio_url_holder[0]:
                print("âš ï¸ æ— è‡ªåŠ¨å­—å¹•ï¼Œå°è¯• ASR...")
                result['transcript'] = await asr_transcribe(audio_url_holder[0], cookies_path)
                if result['transcript']:
                    result['source'] = 'asr'
            else:
                result['error'] = 'è¯¥è§†é¢‘æ²¡æœ‰è‡ªåŠ¨å­—å¹•ä¸”æ— æ³•è·å–éŸ³é¢‘'
        else:
            result['error'] = 'æœªèƒ½è·å–è§†é¢‘ä¿¡æ¯'
        
        await browser.close()
    
    return result


async def asr_transcribe(audio_url: str, cookies_path: str) -> str:
    """ä½¿ç”¨ yt-dlp + Whisper è¿›è¡Œ ASR"""
    print("ğŸ™ï¸  ASR è½¬å†™ä¸­...")
    
    with tempfile.TemporaryDirectory() as tmpdir:
        audio_path = os.path.join(tmpdir, 'audio')
        
        # ä¸‹è½½éŸ³é¢‘
        print("â¬‡ï¸  ä¸‹è½½éŸ³é¢‘...")
        try:
            cmd = [
                'yt-dlp',
                '-f', 'ba',
                '-o', audio_path,
                '--cookies', cookies_path,  # ä½¿ç”¨æ–°é²œ cookies
                '--no-warnings',
                '-q',
                audio_url
            ]
            subprocess.run(cmd, check=True, capture_output=True, timeout=60)
            
            # æ‰¾åˆ°ä¸‹è½½çš„æ–‡ä»¶
            downloaded = None
            for ext in ['.m4a', '.mp4', '.webm', '.mp3']:
                if os.path.exists(audio_path + ext):
                    downloaded = audio_path + ext
                    break
            
            if not downloaded or os.path.getsize(downloaded) < 10000:
                print("âŒ éŸ³é¢‘ä¸‹è½½å¤±è´¥æˆ–æ–‡ä»¶å¤ªå°")
                return None
            
            print(f"âœ… éŸ³é¢‘å·²ä¸‹è½½: {os.path.getsize(downloaded)} bytes")
            
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            return None
        
        # Whisper è½¬å†™
        print("ğŸ“ Whisper è½¬å†™...")
        try:
            import whisper
            
            model = whisper.load_model('base')
            result = model.transcribe(downloaded, language='zh', fp16=False, verbose=False)
            
            transcript = result.get('text', '').strip()
            print(f"âœ… ASR å®Œæˆ: {len(transcript)} å­—ç¬¦")
            return transcript
            
        except Exception as e:
            print(f"âŒ ASR å¤±è´¥: {e}")
            return None


async def main():
    url = sys.argv[1] if len(sys.argv) > 1 else "https://v.douyin.com/od9jc8Ju4t8/"
    
    try:
        result = await extract_with_fresh_cookies(url)
        
        output = {
            "success": bool(result.get('transcript')),
            **result
        }
        
        print("\n" + "="*50)
        print("ğŸ“Š æå–ç»“æœ:")
        print(f"æ ‡é¢˜: {result['title']}")
        print(f"ä½œè€…: {result['author']}")
        print(f"æ—¶é•¿: {result['duration']}ç§’")
        print(f"æ¥æº: {result['source']}")
        print(f"å­—å¹•é•¿åº¦: {len(result['transcript']) if result['transcript'] else 0} å­—ç¬¦")
        
        if result['transcript']:
            print(f"\nğŸ“ å­—å¹•é¢„è§ˆ:\n{result['transcript'][:300]}...")
        
        print("\n===JSON_START===")
        print(json.dumps(output, ensure_ascii=False))
        print("===JSON_END===")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
