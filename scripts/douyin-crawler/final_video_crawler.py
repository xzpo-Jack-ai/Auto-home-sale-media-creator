#!/usr/bin/env python3
"""
æœ€ç»ˆç‰ˆæŠ–éŸ³è§†é¢‘æŠ“å– - åŸºäºå®é™…DOMç»“æ„
"""

import asyncio
import json
import re
import sqlite3
from datetime import datetime
from pathlib import Path
from dataclasses import dataclass
from typing import List
from urllib.parse import quote
from playwright.async_api import async_playwright, Page

COOKIE_FILE = Path(__file__).parent / "cookies.json"
DB_PATH = Path("/Volumes/movespace/workspace/Auto-home-sale-media-creator/apps/api/dev.db")
OUTPUT_DIR = Path(__file__).parent / "output"
OUTPUT_DIR.mkdir(exist_ok=True)

CITIES = ['åŒ—äº¬', 'ä¸Šæµ·', 'æ·±åœ³', 'å¹¿å·', 'æ­å·', 'æˆéƒ½']

@dataclass
class VideoData:
    city: str
    title: str
    author: str
    views: int
    video_url: str
    published_at: datetime


class FinalVideoCrawler:
    def __init__(self):
        self.cookies = json.load(open(COOKIE_FILE))
        self.results: List[VideoData] = []
    
    async def init(self):
        self.playwright = await async_playwright().start()
        self.browser = await self.playwright.chromium.launch(headless=False)
        self.context = await self.browser.new_context(
            viewport={'width': 1400, 'height': 900},
            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        )
        await self.context.add_cookies(self.cookies)
        print("âœ… æµè§ˆå™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def close(self):
        await self.context.close()
        await self.browser.close()
        await self.playwright.stop()
    
    async def crawl_city(self, city: str) -> List[VideoData]:
        """æŠ“å–å•ä¸ªåŸå¸‚"""
        videos = []
        
        try:
            page = await self.context.new_page()
            
            # ç›´æ¥è®¿é—®è§†é¢‘æœç´¢URL
            query = f"{city},æˆ¿äº§"
            url = f"https://creator.douyin.com/creator-micro/creator-count/arithmetic-index/videosearch?query={quote(query)}&source=creator&page=1"
            
            print(f"\nğŸ“ [{city}] è®¿é—®è§†é¢‘æœç´¢...")
            await page.goto(url, wait_until='networkidle', timeout=60000)
            await asyncio.sleep(5)
            
            # å…³é—­å¼¹çª—
            try:
                btn = await page.wait_for_selector('button:has-text("ç¡®è®¤")', timeout=3000)
                if btn:
                    await btn.click()
                    await asyncio.sleep(2)
                    print(f"   âœ… å·²å…³é—­å¼¹çª—")
            except:
                pass
            
            # æ»šåŠ¨åŠ è½½æ›´å¤šå†…å®¹
            await page.evaluate('window.scrollBy(0, 800)')
            await asyncio.sleep(2)
            
            # ä½¿ç”¨JavaScriptæå–è§†é¢‘ä¿¡æ¯ï¼ˆåŸºäºå®é™…å‘ç°çš„DOMç»“æ„ï¼‰
            video_data = await page.evaluate('''() => {
                const results = [];
                const seen = new Set();
                
                // æŸ¥æ‰¾æ‰€æœ‰spanå’Œdivå…ƒç´ 
                const elements = document.querySelectorAll('span, div');
                
                for (const el of elements) {
                    const text = el.textContent.trim();
                    
                    // ç­›é€‰æ¡ä»¶ï¼šé•¿åº¦30-100ï¼ŒåŒ…å«#è¯é¢˜æ ‡ç­¾ï¼Œä¸åŒ…å«å¯¼èˆªèœå•æ–‡å­—
                    if (text.length >= 30 && text.length <= 100 && 
                        text.includes('#') && 
                        !text.includes('é¦–é¡µ') &&
                        !text.includes('å†…å®¹ç®¡ç†') &&
                        !text.includes('æ•°æ®ä¸­å¿ƒ') &&
                        !text.includes('åˆ›ä½œä¸­å¿ƒ')) {
                        
                        // å»é‡
                        if (!seen.has(text)) {
                            seen.add(text);
                            
                            // å°è¯•æ‰¾åˆ°ä½œè€…ï¼ˆçˆ¶å…ƒç´ ä¸­çš„çŸ­æ–‡æœ¬ï¼‰
                            let author = 'æœªçŸ¥ä½œè€…';
                            const parent = el.parentElement;
                            if (parent) {
                                const siblings = parent.querySelectorAll('span, div');
                                for (const sib of siblings) {
                                    const sibText = sib.textContent.trim();
                                    if (sibText.length > 2 && sibText.length < 20 && 
                                        sibText !== text &&
                                        !sibText.includes('#')) {
                                        author = sibText;
                                        break;
                                    }
                                }
                            }
                            
                            results.push({title: text, author});
                        }
                    }
                    
                    if (results.length >= 10) break;
                }
                
                return results;
            }''')
            
            print(f"   âœ… æå–åˆ° {len(video_data)} ä¸ªè§†é¢‘")
            
            for data in video_data:
                videos.append(VideoData(
                    city=city,
                    title=data['title'][:100],
                    author=data['author'][:50],
                    views=100000,  # é»˜è®¤å€¼
                    video_url="",
                    published_at=datetime.now()
                ))
                print(f"      âœ“ {data['title'][:50]}...")
            
            await page.close()
            
        except Exception as e:
            print(f"   âŒ é”™è¯¯: {str(e)[:80]}")
        
        return videos
    
    def save_to_db(self, videos: List[VideoData]):
        if not DB_PATH.exists() or not videos:
            return
        
        try:
            conn = sqlite3.connect(DB_PATH)
            cursor = conn.cursor()
            
            for v in videos:
                vid = f"final_{v.city}_{hash(v.title) % 1000000}_{int(datetime.now().timestamp())}"
                cursor.execute('''
                    INSERT OR REPLACE INTO videos 
                    (id, externalId, platform, title, author, views, 
                     publishedAt, keyword, city, createdAt, updatedAt)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    vid, vid, 'douyin', v.title, v.author, v.views,
                    v.published_at.strftime('%Y-%m-%d %H:%M:%S'),
                    f"{v.city}æˆ¿äº§", v.city,
                    datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                ))
            
            conn.commit()
            conn.close()
            print(f"ğŸ’¾ ä¿å­˜ {len(videos)} æ¡åˆ°æ•°æ®åº“")
            
        except Exception as e:
            print(f"âŒ æ•°æ®åº“é”™è¯¯: {e}")
    
    async def run(self):
        print("=" * 70)
        print("ğŸš€ æœ€ç»ˆç‰ˆæŠ–éŸ³è§†é¢‘æŠ“å–")
        print("=" * 70)
        
        await self.init()
        
        for city in CITIES[:2]:  # å…ˆæµ‹è¯•2ä¸ªåŸå¸‚
            videos = await self.crawl_city(city)
            self.results.extend(videos)
            await asyncio.sleep(3)
        
        if self.results:
            self.save_to_db(self.results)
        
        await self.close()
        
        print("\n" + "=" * 70)
        print(f"âœ… å®Œæˆ: {len(self.results)} æ¡è§†é¢‘")
        for city in CITIES[:2]:
            count = sum(1 for v in self.results if v.city == city)
            print(f"   {city}: {count} æ¡")
        print("=" * 70)


async def main():
    crawler = FinalVideoCrawler()
    await crawler.run()


if __name__ == '__main__':
    asyncio.run(main())
