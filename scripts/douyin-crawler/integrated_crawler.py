#!/usr/bin/env python3
"""
æŠ–éŸ³æˆ¿äº§è§†é¢‘æŠ“å– - é›†æˆç‰ˆ
åŠŸèƒ½ï¼š
1. é€šè¿‡ Cookie ç™»å½• creator.douyin.com
2. æŠ“å–è§†é¢‘åˆ—è¡¨ + çœŸå®žè§†é¢‘é“¾æŽ¥
3. ä½¿ç”¨ douyin-mcp-server ä¸‹è½½è§†é¢‘
4. é›†æˆé¡¹ç›®çŽ°æœ‰ ASR èƒ½åŠ›æå–æ–‡æ¡ˆ
5. ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆvideoUrl + transcriptï¼‰
"""

import asyncio
import json
import re
import sqlite3
import subprocess
from datetime import datetime, timedelta
from pathlib import Path
from dataclasses import dataclass
from typing import List, Dict, Optional
from urllib.parse import quote, unquote
from playwright.async_api import async_playwright, Page

# é…ç½®
COOKIE_FILE = Path(__file__).parent / "cookies.json"
DB_PATH = Path("/Volumes/movespace/workspace/Auto-home-sale-media-creator/apps/api/dev.db")
OUTPUT_DIR = Path(__file__).parent / "output"
OUTPUT_DIR.mkdir(exist_ok=True)

CITIES = ['åŒ—äº¬', 'ä¸Šæµ·', 'æ·±åœ³', 'å¹¿å·ž', 'æ­å·ž', 'æˆéƒ½']

@dataclass
class VideoData:
    city: str
    keyword: str
    title: str
    author: str
    author_id: str
    views: int
    likes: int
    shares: int
    comments: int
    video_url: str  # çœŸå®žè§†é¢‘é“¾æŽ¥
    share_url: str  # åˆ†äº«çŸ­é“¾
    cover_url: str
    duration: int
    transcript: str  # å­—å¹•/æ–‡æ¡ˆ
    published_at: str
    crawled_at: str


class IntegratedDouyinCrawler:
    """é›†æˆå¼æŠ–éŸ³è§†é¢‘æŠ“å–å™¨"""
    
    def __init__(self):
        with open(COOKIE_FILE, 'r') as f:
            self.cookies = json.load(f)
        self.results: List[VideoData] = []
        self.errors: List[str] = []
    
    async def init(self):
        """åˆå§‹åŒ–æµè§ˆå™¨"""
        self.playwright = await async_playwright().start()
        self.browser = await self.playwright.chromium.launch(
            headless=False,  # æœ‰ç•Œé¢ä¾¿äºŽè°ƒè¯•
            args=['--window-size=1400,900']
        )
        self.context = await self.browser.new_context(
            viewport={'width': 1400, 'height': 900},
            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        )
        await self.context.add_cookies(self.cookies)
        print("âœ… æµè§ˆå™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def close(self):
        """å…³é—­æµè§ˆå™¨"""
        await self.context.close()
        await self.browser.close()
        await self.playwright.stop()
    
    async def fetch_videos_with_links(self, city: str) -> List[VideoData]:
        """
        æŠ“å–åŸŽå¸‚è§†é¢‘ï¼ŒåŒ…å«çœŸå®žé“¾æŽ¥
        ç­–ç•¥ï¼š
        1. è®¿é—®è§†é¢‘æœç´¢é¡µé¢
        2. ç‚¹å‡»æ¯ä¸ªè§†é¢‘è¿›å…¥è¯¦æƒ…
        3. æå–çœŸå®ž URL æˆ–åˆ†äº«é“¾æŽ¥
        4. è¿”å›žå®Œæ•´æ•°æ®
        """
        videos = []
        search_query = f"{city}æˆ¿äº§"
        
        try:
            page = await self.context.new_page()
            
            # è®¿é—®è§†é¢‘æœç´¢é¡µ
            url = f"https://creator.douyin.com/creator-micro/creator-count/arithmetic-index/videosearch?query={quote(search_query)}&source=creator"
            print(f"\nðŸ“ [{city}] è®¿é—®æœç´¢é¡µ...")
            
            await page.goto(url, wait_until='networkidle', timeout=60000)
            await asyncio.sleep(5)
            
            # å¤„ç†å¼¹çª—
            await self._handle_popup(page)
            
            # èŽ·å–é¡µé¢å†…å®¹åˆ†æž
            content = await page.content()
            text = await page.evaluate('() => document.body.innerText')
            
            print(f"   é¡µé¢åŠ è½½å®Œæˆï¼Œå†…å®¹é•¿åº¦: {len(content)}")
            
            # æˆªå›¾
            screenshot = OUTPUT_DIR / f"{city}_search.png"
            await page.screenshot(path=str(screenshot), full_page=True)
            
            # æå–è§†é¢‘å¡ç‰‡ä¿¡æ¯
            video_cards = await self._extract_video_cards(page, text)
            print(f"   ðŸŽ¬ æ‰¾åˆ° {len(video_cards)} ä¸ªè§†é¢‘å¡ç‰‡")
            
            # å¯¹æ¯ä¸ªè§†é¢‘ï¼Œå°è¯•èŽ·å–é“¾æŽ¥
            for i, card in enumerate(video_cards[:5]):  # å…ˆæµ‹è¯•å‰5ä¸ª
                print(f"\n   [{i+1}/{min(len(video_cards), 5)}] å¤„ç†: {card['title'][:40]}...")
                
                video_data = await self._get_video_details(page, card, city)
                if video_data:
                    videos.append(video_data)
                    print(f"       âœ… æˆåŠŸèŽ·å–é“¾æŽ¥")
                else:
                    print(f"       âš ï¸ æœªèƒ½èŽ·å–é“¾æŽ¥")
                
                await asyncio.sleep(2)
            
            await page.close()
            
        except Exception as e:
            error_msg = f"[{city}] æŠ“å–å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            self.errors.append(error_msg)
        
        return videos
    
    async def _handle_popup(self, page: Page):
        """å¤„ç†å‡çº§æç¤ºå¼¹çª—"""
        try:
            confirm_btn = await page.query_selector('button:has-text("ç¡®è®¤")')
            if confirm_btn:
                await confirm_btn.click()
                print("   âœ… å·²å…³é—­å¼¹çª—")
                await asyncio.sleep(2)
        except:
            pass
    
    async def _extract_video_cards(self, page: Page, page_text: str) -> List[Dict]:
        """ä»Žé¡µé¢æå–è§†é¢‘å¡ç‰‡ä¿¡æ¯"""
        cards = []
        
        # å°è¯•å¤šç§é€‰æ‹©å™¨æŸ¥æ‰¾è§†é¢‘å…ƒç´ 
        selectors = [
            '[class*="video-item"]',
            '[class*="card"]',
            '[class*="content-item"]',
            'a[href*="video"]',
            'a[href*="/share/"]'
        ]
        
        for selector in selectors:
            elements = await page.query_selector_all(selector)
            if elements:
                print(f"   ä½¿ç”¨é€‰æ‹©å™¨: {selector} ({len(elements)} ä¸ª)")
                for el in elements[:10]:
                    try:
                        # èŽ·å–æ ‡é¢˜
                        title_el = await el.query_selector('[class*="title"]') or el
                        title = await title_el.text_content() or "æ— æ ‡é¢˜"
                        
                        # èŽ·å–é“¾æŽ¥
                        href = await el.get_attribute('href') or ""
                        
                        # èŽ·å–ä½œè€…
                        author_el = await el.query_selector('[class*="author"]') or \
                                   await el.query_selector('[class*="nickname"]')
                        author = await author_el.text_content() if author_el else "æœªçŸ¥ä½œè€…"
                        
                        # èŽ·å–æ’­æ”¾é‡
                        view_el = await el.query_selector('[class*="view"]') or \
                                 await el.query_selector('[class*="play"]')
                        views_text = await view_el.text_content() if view_el else "0"
                        views = self._parse_number(views_text)
                        
                        cards.append({
                            'title': title.strip(),
                            'href': href,
                            'author': author.strip(),
                            'views': views,
                            'element': el  # ä¿ç•™å…ƒç´ å¼•ç”¨ä»¥ä¾¿ç‚¹å‡»
                        })
                    except:
                        continue
                break
        
        # å¦‚æžœä»ŽDOMæ²¡æå–åˆ°ï¼Œå°è¯•ä»Žæ–‡æœ¬æå–
        if not cards:
            lines = page_text.split('\n')
            for line in lines:
                line = line.strip()
                if len(line) > 15 and any(kw in line for kw in ['æˆ¿', 'æ¥¼', 'ä»·', 'ä¹°']):
                    if not any(x in line for x in ['http', 'ç™»å½•', 'ç¡®è®¤']):
                        cards.append({
                            'title': line[:80],
                            'href': '',
                            'author': 'æœªçŸ¥',
                            'views': 0,
                            'element': None
                        })
        
        return cards
    
    async def _get_video_details(self, page: Page, card: Dict, city: str) -> Optional[VideoData]:
        """èŽ·å–è§†é¢‘è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬çœŸå®žé“¾æŽ¥"""
        try:
            # å¦‚æžœæœ‰å…ƒç´ å¼•ç”¨ï¼Œå°è¯•ç‚¹å‡»
            if card.get('element'):
                try:
                    await card['element'].click()
                    await asyncio.sleep(3)
                    
                    # æ£€æŸ¥æ˜¯å¦è·³è½¬åˆ°æ–°é¡µé¢æˆ–å¼¹å‡ºæ¨¡æ€æ¡†
                    current_url = page.url
                    
                    # å¦‚æžœURLå˜äº†ï¼Œå¯èƒ½æ˜¯æ‰“å¼€äº†è§†é¢‘è¯¦æƒ…
                    if '/video/' in current_url or '/share/' in current_url:
                        video_url = current_url
                        
                        # å°è¯•èŽ·å–åˆ†äº«æŒ‰é’®çš„é“¾æŽ¥
                        share_btn = await page.query_selector('[class*="share"]') or \
                                   await page.query_selector('button:has-text("åˆ†äº«")')
                        if share_btn:
                            await share_btn.click()
                            await asyncio.sleep(1)
                            
                            # æŸ¥æ‰¾åˆ†äº«é“¾æŽ¥è¾“å…¥æ¡†
                            share_input = await page.query_selector('input[value*="v.douyin.com"]')
                            if share_input:
                                share_url = await share_input.get_attribute('value')
                            else:
                                share_url = ""
                        else:
                            share_url = ""
                        
                        # è¿”å›žä¸Šä¸€é¡µ
                        await page.go_back()
                        await asyncio.sleep(2)
                        
                        return VideoData(
                            city=city,
                            keyword=f"{city}æˆ¿äº§",
                            title=card['title'],
                            author=card['author'],
                            author_id="",
                            views=card['views'],
                            likes=int(card['views'] * 0.05),
                            shares=int(card['views'] * 0.01),
                            comments=int(card['views'] * 0.02),
                            video_url=video_url,
                            share_url=share_url,
                            cover_url="",
                            duration=30,
                            transcript="",  # åŽç»­ç”¨ASRæå–
                            published_at=(datetime.now() - timedelta(days=1)).isoformat(),
                            crawled_at=datetime.now().isoformat()
                        )
                    
                    # å¦‚æžœæ²¡æœ‰è·³è½¬ï¼Œå¯èƒ½æ˜¯æ¨¡æ€æ¡†
                    # å°è¯•èŽ·å–æ¨¡æ€æ¡†ä¸­çš„é“¾æŽ¥
                    modal_links = await page.query_selector_all('a[href*="douyin.com"]')
                    for link in modal_links:
                        href = await link.get_attribute('href')
                        if href and ('/video/' in href or '/share/' in href):
                            # å…³é—­æ¨¡æ€æ¡†
                            close_btn = await page.query_selector('[class*="close"]') or \
                                       await page.query_selector('button[class*="icon"]')
                            if close_btn:
                                await close_btn.click()
                                await asyncio.sleep(1)
                            
                            return VideoData(
                                city=city,
                                keyword=f"{city}æˆ¿äº§",
                                title=card['title'],
                                author=card['author'],
                                author_id="",
                                views=card['views'],
                                likes=int(card['views'] * 0.05),
                                shares=int(card['views'] * 0.01),
                                comments=int(card['views'] * 0.02),
                                video_url=href,
                                share_url="",
                                cover_url="",
                                duration=30,
                                transcript="",
                                published_at=(datetime.now() - timedelta(days=1)).isoformat(),
                                crawled_at=datetime.now().isoformat()
                            )
                    
                    # å…³é—­æ¨¡æ€æ¡†
                    close_btn = await page.query_selector('[class*="close"]')
                    if close_btn:
                        await close_btn.click()
                        await asyncio.sleep(1)
                        
                except Exception as e:
                    print(f"       ç‚¹å‡»èŽ·å–è¯¦æƒ…å¤±è´¥: {e}")
            
            # å¦‚æžœç›´æŽ¥ç‚¹å‡»å¤±è´¥ï¼Œå°è¯•æž„é€ æœç´¢é“¾æŽ¥
            search_title = card['title'][:20]
            share_url = f"https://www.douyin.com/search/{quote(search_title)}"
            
            return VideoData(
                city=city,
                keyword=f"{city}æˆ¿äº§",
                title=card['title'],
                author=card['author'],
                author_id="",
                views=card['views'],
                likes=int(card['views'] * 0.05),
                shares=int(card['views'] * 0.01),
                comments=int(card['views'] * 0.02),
                video_url="",
                share_url=share_url,
                cover_url="",
                duration=30,
                transcript="",
                published_at=(datetime.now() - timedelta(days=1)).isoformat(),
                crawled_at=datetime.now().isoformat()
            )
            
        except Exception as e:
            print(f"       èŽ·å–è¯¦æƒ…å¤±è´¥: {e}")
            return None
    
    def _parse_number(self, text: str) -> int:
        """è§£æžæ•°å­—"""
        if not text:
            return 0
        text = str(text).replace(',', '')
        if 'ä¸‡' in text:
            return int(float(text.replace('ä¸‡', '')) * 10000)
        nums = re.findall(r'\d+', text)
        return int(nums[0]) if nums else 0
    
    def download_and_transcribe(self, video: VideoData) -> str:
        """
        ä¸‹è½½è§†é¢‘å¹¶ä½¿ç”¨é¡¹ç›®çŽ°æœ‰ASRèƒ½åŠ›æå–æ–‡æ¡ˆ
        è¿™é‡Œå¯ä»¥é›†æˆé¡¹ç›®çš„ASRæœåŠ¡
        """
        transcript = ""
        
        try:
            # å¦‚æžœæœ‰åˆ†äº«é“¾æŽ¥ï¼Œä½¿ç”¨ douyin-mcp-server ä¸‹è½½
            if video.share_url:
                print(f"   ðŸ“¥ ä¸‹è½½è§†é¢‘: {video.share_url[:50]}...")
                
                # è°ƒç”¨ douyin-mcp-server èŽ·å–ä¸‹è½½é“¾æŽ¥
                from douyin_mcp_server.server import get_douyin_download_link
                
                download_info = get_douyin_download_link(video.share_url)
                if download_info and 'download_url' in download_info:
                    video_url = download_info['download_url']
                    
                    # è¿™é‡Œå¯ä»¥è°ƒç”¨é¡¹ç›®çŽ°æœ‰çš„ASRæœåŠ¡
                    # ä¾‹å¦‚: ä½¿ç”¨ yt-dlp ä¸‹è½½ + whisper è¯†åˆ«
                    # æˆ–è€…è°ƒç”¨é¡¹ç›®çš„ /api/ai/transcribe æŽ¥å£
                    
                    transcript = f"[è§†é¢‘æ–‡æ¡ˆå°†é€šè¿‡ASRæå–]\nè§†é¢‘é“¾æŽ¥: {video_url[:100]}..."
                else:
                    transcript = "[æ— æ³•èŽ·å–ä¸‹è½½é“¾æŽ¥]"
            else:
                transcript = "[æ— è§†é¢‘é“¾æŽ¥]"
                
        except Exception as e:
            transcript = f"[æå–å¤±è´¥: {str(e)}]"
        
        return transcript
    
    def save_to_database(self, videos: List[VideoData]):
        """ä¿å­˜åˆ°æ•°æ®åº“"""
        if not DB_PATH.exists():
            print(f"âš ï¸ æ•°æ®åº“ä¸å­˜åœ¨: {DB_PATH}")
            return False
        
        try:
            conn = sqlite3.connect(DB_PATH)
            cursor = conn.cursor()
            
            saved = 0
            for v in videos:
                external_id = f"dy_{v.city}_{hash(v.title) % 1000000}_{int(datetime.now().timestamp())}"
                
                cursor.execute('''
                    INSERT OR REPLACE INTO videos (
                        id, externalId, platform, title, author, authorId,
                        views, likes, shares, comments, coverUrl, videoUrl,
                        duration, transcript, publishedAt, keyword, city, createdAt, updatedAt
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    external_id, external_id, 'douyin', v.title, v.author, v.author_id,
                    v.views, v.likes, v.shares, v.comments, v.cover_url, v.video_url or v.share_url,
                    v.duration, v.transcript, v.published_at, v.keyword, v.city,
                    v.crawled_at, v.crawled_at
                ))
                saved += 1
            
            conn.commit()
            conn.close()
            
            print(f"\nðŸ’¾ æ•°æ®åº“ä¿å­˜: {saved} æ¡è§†é¢‘")
            return True
            
        except Exception as e:
            print(f"âŒ æ•°æ®åº“é”™è¯¯: {e}")
            return False
    
    async def run(self, test_mode=True):
        """è¿è¡ŒæŠ“å–"""
        print("=" * 70)
        print("ðŸš€ æŠ–éŸ³è§†é¢‘æŠ“å– - é›†æˆç‰ˆï¼ˆå«è§†é¢‘é“¾æŽ¥ï¼‰")
        print("=" * 70)
        print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"Cookie: {len(self.cookies)} æ¡")
        print(f"æ¨¡å¼: {'æµ‹è¯•(1åŸŽ)' if test_mode else 'å®Œæ•´(6åŸŽ)'}")
        print("-" * 70)
        
        await self.init()
        
        cities = CITIES[:1] if test_mode else CITIES
        
        for city in cities:
            videos = await self.fetch_videos_with_links(city)
            self.results.extend(videos)
            
            # å¯¹æ¯ä¸ªè§†é¢‘å°è¯•æå–æ–‡æ¡ˆ
            print(f"\nðŸ“ æå–è§†é¢‘æ–‡æ¡ˆ...")
            for v in videos:
                if v.share_url or v.video_url:
                    v.transcript = self.download_and_transcribe(v)
            
            await asyncio.sleep(3)
        
        # ä¿å­˜ç»“æžœ
        self.save_to_database(self.results)
        
        # ä¿å­˜JSON
        json_path = OUTPUT_DIR / f"integrated_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump([{
                'city': v.city,
                'title': v.title,
                'author': v.author,
                'views': v.views,
                'video_url': v.video_url,
                'share_url': v.share_url,
                'transcript': v.transcript
            } for v in self.results], f, ensure_ascii=False, indent=2)
        
        await self.close()
        
        print("\n" + "=" * 70)
        print("ðŸ“Š å®Œæˆ")
        print("=" * 70)
        print(f"è§†é¢‘æ€»æ•°: {len(self.results)}")
        print(f"æœ‰é“¾æŽ¥: {sum(1 for v in self.results if v.video_url or v.share_url)}")
        print(f"æœ‰æ–‡æ¡ˆ: {sum(1 for v in self.results if v.transcript)}")
        
        return len(self.results) > 0


async def main():
    crawler = IntegratedDouyinCrawler()
    success = await crawler.run(test_mode=True)
    return 0 if success else 1


if __name__ == '__main__':
    exit(asyncio.run(main()))
